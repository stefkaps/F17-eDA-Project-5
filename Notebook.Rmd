---
title: "Final Project: Global Burden of Disease"
author: 'Group 2: Kelly Jennings, Stefanos Kapetanakis, Marcus Martinez, Rachel Tarrant, Changyong Yi'
resource_files:
- .Renviron
output:
  html_notebook:
    code_folding: hide
    toc: yes
    toc_depth: 4
    toc_float: yes
runtime: shiny
---

```{r setup, include=FALSE}
library(tidyverse)
library(modelr)
require(MASS)
require(ROCR)
require(ISLR)
require(ggplot2)
library(leaps)
library(glmnet)
require(tree)
require(randomForest)
require(gbm)
require(e1071)
require(dplyr)
require(shiny)
require(data.world)
knitr::opts_chunk$set(echo = TRUE)
```
  
## **R Session Info**  

```{r}
sessionInfo()
```

## **Github Link** 
[https://github.com/stefkaps/F17-eDA-Project-5](https://github.com/stefkaps/F17-eDA-Project-5)

## **Data.World Link**
[https://data.world/tarrantrl/f-17-eda-project-5](https://data.world/tarrantrl/f-17-eda-project-5)

## **Connecting to data.world** 
```{r}
project <- "https://data.world/kellyjennings/disease"
data.world::set_config(cfg_env("DW_API"))
df <- data.world::query(
  data.world::qry_sql("SELECT * FROM GlobalBurdenofDisease_Europe"),
  dataset = project
)
```

## Setup
We created several dataframes for our analyses. 
The first thing we did was convert the ages to all be in units of years (since some measurements in the dataset were in days). We no longer needed the column age_name_unit after standardizing the age units.
In addition, there were some variables that we excluded from all our analyses because they were not meaningful as predictors. These included cause_medium and cause_short, which were just different versions of the full cause name.

```{r}
df_allyears <- df %>% dplyr::mutate(., age_name_from2 = ifelse(age_name_unit == "days", age_name_from/365, age_name_from)) %>% dplyr::mutate(., age_name_upto2 = ifelse(age_name_upto == "days", age_name_upto/365, age_name_upto)) %>% dplyr::select(., -age_name_upto, -age_name_from,-age_name_unit, -cause_medium, -cause_short)

```

## **Introduction** 
In our final project, we decided to examine a fairly large dataset regarding the global burden of disease. This dataset, provided by a study done by the Institute for Health Metrics and Evaluation, inluded information on number of deaths, death percent, death rate, years of life lost, years of life lived with a disability, life years adjusted for disability, and the causes of these measures. 

Description from data source:

"Statistics measured by the Global Burden of Disease (GBD) Study compiled by the Institute for Health Metrics and Evaluation (IHME). This study estimates the burden of diseases, injuries, and risk factors for the global population and specific regions and is a collaboration between the IHME and the University of Queensland, Harvard School of Public Health, Johns Hopkins Bloomberg School of Public Health, University of Tokyo, Imperial College London and the WHO."

Schema from data source:

"Cause Full Name Full Name of the Cause

Cause (Medium) Moderately Shortened Name of the Cause

Cause (Short) Fully Shortened Name of the Cause

Region Name Region name; the full list of regions are as shown : Global; High-income Asia Pacific; Western Europe; Australasia; High-income North America; Central Europe; Southern Latin America; Eastern Europe; East Asia; Tropical Latin America; Central Latin America; Southeast Asia; Central Asia; Andean latin America; North Africa and Middle East; Caribbean; South Asia; Oceania; Southern sub-Saharan Africa; Eastern sub-Saharan Africa; Central sub-Saharan Africa; Western sub-Saharan Africa

Year Year : 1990; 2005; 2010

Age Min. Minimum age for this age group; the full list of age groups are as shown : 0-6 days; 7-27 days; 28-364 days; 1-4 years; 5-9 years; 10-14 years; 15-19 years; 20-24 years; 25-29 years; 30-34 years; 35-39 years; 40-44 years; 50-54 years; 55-59 years; 60-64 years; 65-69 years; 70-74 years; 75-79 years; 80+ years; All ages

Age Max. Maximum age for this age group; the full list of age groups are as shown : 0-6 days; 7-27 days; 28-364 days; 1-4 years; 5-9 years; 10-14 years; 15-19 years; 20-24 years; 25-29 years; 30-34 years; 35-39 years; 40-44 years; 50-54 years; 55-59 years; 60-64 years; 65-69 years; 70-74 years; 75-79 years; 80+ years; All ages

Age Unit Age group units; the full list of age groups are as shown : 0-6 days; 7-27 days; 28-364 days; 1-4 years; 5-9 years; 10-14 years; 15-19 years; 20-24 years; 25-29 years; 30-34 years; 35-39 years; 40-44 years; 50-54 years; 55-59 years; 60-64 years; 65-69 years; 70-74 years; 75-79 years; 80+ years; All ages

Sex Sex : Male; Female; Both

No. of Deaths Number of Deaths

No. of Deaths (UI Min.) DNumber of Deaths - 95% Uncertainty Interval Minimum Value

No. of Deaths (UI Max.) DNumber of Deaths - 95% Uncertainty Interval Maximum Value

Death Pct. Death Percent of All Causes

Death Pct. (UI Min.) Death Percent of All Causes - 95% Uncertainty Interval Minimum Value

Death Pct. (UI Max.) Death Percent of All Causes - 95% Uncertainty Interval Maximum Value

Death Rate Death Rate Per 100,000

Death Rate (UI Min.) Death Rate Per 100,000 - 95% Uncertainty Interval Minimum Value

Death Rate (UI Max.) Death Rate Per 100,000 - 95% Uncertainty Interval Maximum Value

No. of YLL Number of Years of Life Lost (YLL)

No. of YLL (UI Min.) Number of Years of Life Lost (YLL) - 95% Uncertainty Interval Minimum Value

No. of YLL (UI Max.) Number of Years of Life Lost (YLL) - 95% Uncertainty Interval Maximum Value

YLL Pct. Years of Life Lost (YLL) Percent of All Causes

YLL Pct. (UI Min.) Years of Life Lost (YLL) Percent of All Causes - 95% Uncertainty Interval Minimum Value

YLL Pct. (UI Max.) Years of Life Lost (YLL) Percent of All Causes - 95% Uncertainty Interval Maximum Value

YLL Rate Years of Life Lost (YLL) Rate Per 100,000

YLL Rate (UI Min.) Years of Life Lost (YLL) Rate Per 100,000 - 95% Uncertainty Interval Minimum Value

YLL Rate (UI Max.) Years of Life Lost (YLL) Rate Per 100,000 - 95% Uncertainty Interval Maximum Value

No. of YLD Number of Years Lived with Disability (YLD)

No. of YLD (UI Min.) Number of Years Lived with Disability (YLD) - 95% Uncertainty Interval Minimum Value

No. of YLD (UI Max.) Number of Years Lived with Disability (YLD) - 95% Uncertainty Interval Maximum Value

YLD Pct. Years Lived with Disability (YLD) Percent of All Causes

YLD Pct. (UI Min.) Years Lived with Disability (YLD) Percent of All Causes - 95% Uncertainty Interval Minimum Value

YLD Pct. (UI Max.) Years Lived with Disability (YLD) Percent of All Causes - 95% Uncertainty Interval Maximum Value

YLD Rate Years Lived with Disability (YLD) Rate Per 100,000

YLD Rate (UI Min.) Years Lived with Disability (YLD) Rate Per 100,000 - 95% Uncertainty Interval Minimum Value

YLD Rate (UI Max.) Years Lived with Disability (YLD) Rate Per 100,000 - 95% Uncertainty Interval Miaximum Value

No. of DALY Number of Disability Adjusted Life Years (DALY)

No. of DALY (UI Min.) Number of Disability Adjusted Life Years (DALY) - 95% Uncertainty Interval Minimum Value

No. of DALY (UI Max.) Number of Disability Adjusted Life Years (DALY) - 95% Uncertainty Interval Maximum Value

DALY Pct. Disability Adjusted Life Years (DALY) Percent of All Causes

DALY Pct. (UI Min.) Disability Adjusted Life Years (DALY) Percent of All Causes - 95% Uncertainty Interval Minimum Value

DALY Pct. (UI Max.) Disability Adjusted Life Years (DALY) Percent of All Causes - 95% Uncertainty Interval Maximum Value

DALY Rate Years Lived with Disability (YLD) Rate Per 100,000

DALY Rate (UI Min.) Years Lived with Disability (YLD) Rate Per 100,000 - 95% Uncertainty Interval Minimum Value

DALY Rate (UI Max.) Years Lived with Disability (YLD) Rate Per 100,000 - 95% Uncertainty Interval Maximum Value" 
This description is taken from the original source: [Institute for Health Metrics and Evaluation - Global Burden of Disease.](http://www.healthmetricsandevaluation.org/ghdx/record/global-burden-disease-study-2010-gbd-2010-results-cause-1990-2010)

Throughout our analyses of these data, we generally focused on Europe  (Western and Eastern Europe), rather than the whole dataset. However, we looked at a variety of subsets of the data, including specific years, specific disease types, etc. There was a lot to be learned here, but the areas we gave particular attention to were: 

## Death_abs
Interesting finding: The model based on boosting predictors did somewhat better in terms of adjusted r-squared than a model based on predictors found in both lasso and boosting analyses. The differences are very small, and, in fact, we see that the standard error for the two predictors used in the second model may be smaller than the standard error for the same predictors in the previous model. However, when we only look at r-squared values, we see the following order in terms of performance- Model 1 (yll_abs_ui_from, yll_abs, yll_abs_ui_upto), Random Forest, Model 2 (yll_abs_ui_from, yll_abs).

### Boosting Model

[Boosting to find important predictors for death_abs](https://data.world/tarrantrl/f-17-eda-project-5/insights/26c94e87-2611-4bcc-b851-6d938ff1e45d)

For this analysis, we excluded categorical variables for ease of computation. We also excluded death_abs_ui_upto and death_abs_ui_from because these are different aspects of the death_abs measurement itself and are therefore not valid predictors of death_abs.

```{r}
df_deathabs=dplyr::select(df_allyears, -cause_name, -region_name, -sex_name, -death_abs_ui_upto, -death_abs_ui_from)
set.seed(1)
train_deathabs = sample(1:nrow(df_deathabs),7000)
#dfb=dplyr::sample_n(dfb, 3000)
boost.deathabs=gbm(death_abs~.,data=df_deathabs[train_deathabs,],distribution="gaussian",n.trees=500,shrinkage=0.01,interaction.depth=4)
summary(boost.deathabs,plotit=FALSE)
```

This selected yll_abs_ui_from, yll_abs, death_pct_ui_from, daly_abs, and yll_abs_ui_upto as the variables that contributed the most.

```{r} 
# # SOMETHING ISN'T RIGHT WITH THIS- 55000000 mse
# df_test_deathabs = df_deathabs[-train_deathabs,]
# test_deathabs = sample(1:nrow(df_test_deathabs),7000)
# n.trees_d=seq(from=100,to=500,by=100)
# predmat_deathabs=predict(boost.deathabs,newdata=df_test_deathabs[test_deathabs,],n.trees=n.trees_d)
# summary(predmat_deathabs)
# berr_deathabs=with(df_test_deathabs[test_deathabs,],apply( (predmat_deathabs-death_abs)^2,2,mean))
# ```
# ```{r}
# renderPlot({
#   plot(n.trees_d,berr_deathabs,pch=19,ylab="Mean Squared Error", xlab="# Trees",main="Boosting Test Error")
#   abline(h=min(berr_deathabs),col="red")
# })
```


### Model 1 Linear Regression

[Multi-predictor Linear Regression Model for death_abs](https://data.world/tarrantrl/f-17-eda-project-5/insights/2c1db0df-9dae-4b4c-a816-d862f903a179)

Having seen the predictors the boosting model chose as the "best," we decided to see how they would fare in classic linear regression.

```{r}
df_deathabs_lr1=dplyr::select(df, -cause_name, -cause_medium, -cause_short, -region_name, -sex_name, -age_name_unit, -death_abs_ui_upto, -death_abs_ui_from)
df_deathabs_lr1=dplyr::sample_n(df_deathabs_lr1, 10000)
#df_deathabslr_nona = na.omit(df_deathabs_lr)
#Original Predictors#
fitDeathAbs1 = lm(death_abs~yll_abs_ui_from + yll_abs + yll_abs_ui_upto,data=df_deathabs_lr1)
fitDeathAbs1
summary(fitDeathAbs1)
```

As you can see above, the results were pretty good! Namely, we had a fairly high r-squared value and a very small p-value.

### Backwards/Forwards Stepwise Selection

[Backwards, Forwards, and Best Subset Selection for death_abs](https://data.world/tarrantrl/f-17-eda-project-5/insights/3350db18-efb4-4359-92bd-c64b0f3274f5)

```{r}
df_deathabs_bs=dplyr::select(df, -cause_name, -cause_medium, -cause_short, -region_name, -sex_name, -age_name_unit, -death_abs_ui_upto, -death_abs_ui_from)
df_deathabs_bs=dplyr::sample_n(df_deathabs_bs, 10000)
#attach(df_deathabs)

#Forward#
regfit.fwd=regsubsets(death_abs~.,data=df_deathabs_bs,nvmax=37,method="forward")
#summary(regfit.fwd)
regfwd.summary=summary(regfit.fwd)
which.min(regfwd.summary$cp)
which.max(regfwd.summary$adjr2)
```

```{r}
renderPlot(plot(regfit.fwd,scale="Cp"))
renderPlot(plot(regfit.fwd,scale="adjr2"))
renderPlot(plot(regfwd.summary$cp,xlab="Number of Variables",ylab="Cp"))
renderPlot(plot(regfwd.summary$adjr2,xlab="Number of Variables",ylab="adjr2"))
```

```{r}
# backwards
regfit.bwd=regsubsets(death_abs~.,data=df_deathabs_bs,nvmax=37,method="backward")
#summary(regfit.bwd)
regbwd.summary=summary(regfit.bwd)
which.min(regbwd.summary$cp)
which.max(regbwd.summary$adjr2)
```

```{r}
renderPlot(plot(regfit.bwd,scale="Cp"))
renderPlot(plot(regfit.bwd,scale="adjr2"))
renderPlot(plot(regbwd.summary$cp,xlab="Number of Variables",ylab="Cp"))
renderPlot(plot(regbwd.summary$adjr2,xlab="Number of Variables",ylab="adjr2"))
```

As you can see, in the above plots for forward and backward stepwise selection, they produced relatively similar results, suggesting the best model uses the majority of our predictors.

### Lasso on death_abs

[Lasso on death_abs](https://data.world/tarrantrl/f-17-eda-project-5/insights/2d587ac9-73ff-49ec-9b48-1094cca839b1)

```{r}
df_deathabs_lasso=dplyr::select(df, -cause_name, -cause_medium, -cause_short, -region_name, -sex_name, -age_name_unit, -death_abs_ui_upto, -death_abs_ui_from)
df_deathabs_lasso=dplyr::sample_n(df_deathabs_lasso, 10000)
df_deathabs_nona <- na.omit(df_deathabs_lasso)
#attach(df_deathabs_nona)
x=model.matrix(death_abs~.-1,data=df_deathabs_nona) 
y=df_deathabs_nona$death_abs
fit.lasso=glmnet(x,y,family="gaussian")
cv.lasso=cv.glmnet(x,y,family="gaussian")
coef(cv.lasso)
```

```{r}
renderPlot(plot(fit.lasso,xvar="lambda",label=TRUE)) 
renderPlot(plot(cv.lasso))
```

This yielded similar results to the original boosting model, but ultimately excluded one variable boosting did not. From this, we ended up running the linear regression model below, with the two best predictors both Lasso and Boosting chose.


### Model 2 Linear Regression

[Linear Regression on death_abs with Updated Predictors](https://data.world/tarrantrl/f-17-eda-project-5/insights/b4a21227-5c31-4120-9b0e-0c2e7207c9fc)

```{r}
df_deathabs_lr=dplyr::select(df, -cause_name, -cause_medium, -cause_short, -region_name, -sex_name, -age_name_unit, -death_abs_ui_upto, -death_abs_ui_from)
df_deathabs_lr=dplyr::sample_n(df_deathabs_lr, 10000)
#Updated Predictors#
fitDeathAbs = lm(death_abs~yll_abs_ui_from + yll_abs,data=df_deathabs_lr)
fitDeathAbs
summary(fitDeathAbs)
```

### Random Forest on death_abs

[Random Forest on death_abs](https://data.world/tarrantrl/f-17-eda-project-5/insights/230157c7-8aed-4067-b57f-6b8bf34ab6f6)

The random forest code takes a long time to run, so this is just a sample. See the more accurate results in this insight [here.](https://data.world/tarrantrl/f-17-eda-project-5/insights/230157c7-8aed-4067-b57f-6b8bf34ab6f6)

```{r}
##Random Forests Section- trees and mtry reduced
df_deathabs_rf=dplyr::select(df, -cause_name, -cause_medium, -cause_short, -region_name, -sex_name, -age_name_unit, -death_abs_ui_upto, -death_abs_ui_from)
set.seed(11)
df_deathabs_rf=dplyr::sample_n(df_deathabs_rf, 10000)
df_deathabsrf_nona = na.omit(df_deathabs_rf)
#attach(df_deathabsrf_nona)
set.seed(101)
dim(df_deathabsrf_nona)
train=sample(1:nrow(df_deathabsrf_nona),2000)
rf.death=randomForest(death_abs~.,data=df_deathabsrf_nona,subset=train)
rf.death
oob.err=double(6)
test.err=double(6)
for(mtry in 1:6){
  fit=randomForest(death_abs~.,data=df_deathabsrf_nona,subset=train,mtry=mtry,ntree=50)
  oob.err[mtry]=fit$mse[50]
  pred=predict(fit,df_deathabsrf_nona[-train,])
  test.err[mtry]=with(df_deathabsrf_nona[-train,],mean((death_abs-pred)^2))
  cat(mtry," ")
}
```

```{r}
renderPlot({
  matplot(1:mtry,cbind(test.err,oob.err),pch=19,col=c("red","blue"),type="b",ylab="Mean Squared Error")
  legend("topright",legend=c("OOB","Test"),pch=19,col=c("red","blue"))
})
```

As mentioned in the overview above, this random forest analysis yields similar results in terms of r-squared as both the above linear regression models. In fact, its r-squared value lies right in the middle.

## YLL_abs
Interesting finding: The predictors chosen in both the boosting and lasso analyses fared well in linear regression, having a significant p-value for the model and a very high r-squared value. This linear regression model was a much better fit than just using the predictors chosen from boosting. Also, the linear regression model using just the predictors from the lasso analysis seemed to overfit. Interestingly, best subset selection showed the best model is around 12 predictors, foreward selection showed the best model is around 8 predictors, and backwards selection showed the best model is around 4 predictors. It was interesting these selections chose models with such different numbers of predictors.

### Boosting Model

[Boosting to Find Best Predictors of yll_abs](https://data.world/tarrantrl/f-17-eda-project-5/insights/743d8695-b85b-49ac-b537-05f0b554b809)

```{r}
df_yll_abs_b=dplyr::select(df, -cause_name, -cause_medium, -cause_short, -region_name, -sex_name, -age_name_unit, -yll_abs_ui_upto, -yll_abs_ui_from)
df_yll_abs_b=dplyr::sample_n(df_yll_abs_b, 10000)
boost.dfb=gbm(yll_abs~.,data=df_yll_abs_b,distribution="gaussian",n.trees=200,shrinkage=0.01,interaction.depth=4)
summary(boost.dfb, plotit=FALSE)
```

The top 7 predictors chosen in this boosting analysis for yll_abs were death_abs_ui_upto, daly_abs_ui_from, death_abs, death_abs_ui_from, daly_abs, daly_abs_ui_upto, & death_pct_ui_from. It makes sense that the number of death predictors are the best predictors for years of life lost since people with diseases are more likely to have years of their lives lost due to dying from the disease. 

### Model 1 Linear Regression with Boosting Predictors

```{r}
# LR with top 7 Boosting Predictors
df_yll_abs_lr=dplyr::select(df, -cause_name, -cause_medium, -cause_short, -region_name, -sex_name, -age_name_unit)
df_yll_abs_lr=dplyr::sample_n(df_yll_abs_lr, 10000)
#attach(df_yll_abs)
#df_nona_yll = na.omit(df_yll_abs)
#attach(df_nona_yll)
fitYLLAbs = lm(yll_abs~death_abs_ui_upto + daly_abs_ui_from + death_abs + death_abs_ui_from + daly_abs + daly_abs_ui_upto + death_pct_ui_from,data=df_yll_abs_lr)
fitYLLAbs
summary(fitYLLAbs)
```

In this linear regression model, we used the top 7 predictors from the boosting analysis to predit yll_abs. The small p-value shows that these are good predictors for yll_abs. Also, the r-squared was fairly high.


### Lasso

[Lasso Analysis on yll_abs](https://data.world/tarrantrl/f-17-eda-project-5/insights/5ff96be6-c362-4ae9-bd61-6e5c9409b0da)

```{r}
df_yll_abs_l=dplyr::select(df, -cause_name, -cause_medium, -cause_short, -region_name, -sex_name, -age_name_unit, -yll_abs_ui_upto, -yll_abs_ui_from)
df_yll_abs_l=dplyr::sample_n(df_yll_abs_l, 10000)
df1_nona_l <- na.omit(df_yll_abs_l)
#attach(df1_nona)
# for this you have to pass in a matrix of x. You have to construct the x's
xl=model.matrix(yll_abs~.-1,data=df1_nona_l) 
# and construct the y's
yl=df1_nona_l$yll_abs
fit.lasso1=glmnet(xl,yl,family="gaussian")
# do cross validation for each lambda (default is kfold of 10 across 100 lambdas)
cv.lasso1=cv.glmnet(xl,yl,family="gaussian")
# get the coefficients for what it thinks is the best model
coef(cv.lasso1)
```

Interestingly, death_abs_ui_from and death_abs were not included, yet they were among the top predictors in boosting analysis. Also, death_abs_ui_upto, daly_abs, and daly_abs_ui_from were chosen in the top 7 predictors for boosting, and they were predictors that lasso did not reduce to zero. This is further evidence that these three predictors are probably the best for predicting yll_abs.  

```{r}
# plot how lambda is changing against the model fit
renderPlot(plot(fit.lasso1,xvar="lambda",label=TRUE))
# plot the cross validation mean squared errors of all 100 models
renderPlot(plot(cv.lasso1))
```

### Model 2 Linear Regression with Lasso Predictors
```{r}
df_yll_abs_lr=dplyr::select(df, -cause_name, -cause_medium, -cause_short, -region_name, -sex_name, -age_name_unit)
df_yll_abs_lr=dplyr::sample_n(df_yll_abs_lr, 10000)
#attach(df_yll_abs)
#df_nona_yll = na.omit(df_yll_abs)
#attach(df_nona_yll)
fitYLLAbs = lm(yll_abs~death_abs_ui_upto + death_pct + yld_abs + yld_abs_ui_from + yld_abs_ui_upto + daly_abs + daly_abs_ui_from,data=df_yll_abs_lr)
fitYLLAbs
summary(fitYLLAbs)
```
This model is too perfect, since the adjusted r-squared is 1. We believe that this is due to overfitting. Due to this, we made another linear regression model that only used the predictors that were included in both the boosting and lasso anlyses. This model can be seen in the next section.

### Model 3 Linear Regression with Boosting & Lasso Predictors

[Linear Regression on yll_abs](https://data.world/tarrantrl/f-17-eda-project-5/insights/8593766c-f3de-4a3d-a054-a91dc9130785)

```{r}
# LR with Predictors that were in both Lasso & Boosting
df_yll_abs_lr=dplyr::select(df, -cause_name, -cause_medium, -cause_short, -region_name, -sex_name, -age_name_unit)
df_yll_abs_lr=dplyr::sample_n(df_yll_abs_lr, 10000)
#attach(df_yll_abs)
#df_nona_yll = na.omit(df_yll_abs)
#attach(df_nona_yll)
fitYLLAbs = lm(yll_abs~death_abs_ui_upto + daly_abs + daly_abs_ui_from,data=df_yll_abs_lr)
fitYLLAbs
summary(fitYLLAbs)
```

In this model, we used the predictors death_abs_ui_upto, daly_abs, and daly_abs_ui_from. We chose these predictors since they were the ones that were included in both the lasso and boosting anlyses. The small p-values are more evidence that these three predictors are good at predicting yll_abs. Also, the r-squared was fairly high, and higher than that of the first model. This model was much better than the previous one too, where we used only the top 7 predictors from the boosting analysis. 


### Best Subset Selection

[Best Subset Selection for yll_abs](https://data.world/tarrantrl/f-17-eda-project-5/insights/e85e9b69-9203-4244-ad1d-a543c6c76036)

```{r}
df_yll_abs_sub=dplyr::select(df, -cause_name, -cause_medium, -cause_short, -region_name, -sex_name, -age_name_unit, -yll_abs_ui_upto, -yll_abs_ui_from)
df_yll_abs_sub=dplyr::sample_n(df_yll_abs_sub, 5000)
#attach(df2)
regfit.full=regsubsets(yll_abs~.,data=df_yll_abs_sub, nvmax=37)
reg.summary=summary(regfit.full)
names(reg.summary)
which.min(reg.summary$cp)
which.max(reg.summary$adjr2)
#summary(regfit.full)
coef(regfit.full,10)
```

```{r}
renderPlot(plot(reg.summary$cp,xlab="Number of Variables",ylab="Cp"))
renderPlot(plot(reg.summary$adjr2,xlab="Number of Variables",ylab="adjr2"))
renderPlot(plot(regfit.full,scale="Cp"))
renderPlot(plot(regfit.full,scale="adjr2"))
```

### Forwards/Backwards Stepwise Selection

```{r}
regfit.fwd1=regsubsets(yll_abs~.,data=df_yll_abs_sub,nvmax=37,method="forward")
#summary(regfit.fwd1)
regfwd.summary1=summary(regfit.fwd1)
which.min(regfwd.summary1$cp)
which.max(regfwd.summary1$adjr2)
```

```{r}
renderPlot(plot(regfit.fwd1,scale="Cp"))
renderPlot(plot(regfit.fwd1,scale="adjr2"))
renderPlot(plot(regfwd.summary1$cp,xlab="Number of Variables",ylab="Cp"))
renderPlot(plot(regfwd.summary1$adjr2,xlab="Number of Variables",ylab="adjr2"))
```

```{r}
#Backward#
regfit.bwd1=regsubsets(yll_abs~.,data=df_yll_abs_sub,nvmax=37,method="backward")
#summary(regfit.bwd1)
regbwd.summary1=summary(regfit.bwd1)
which.min(regbwd.summary1$cp)
which.max(regbwd.summary1$adjr2)
```

```{r}
renderPlot(plot(regfit.bwd1,scale="Cp"))
renderPlot(plot(regfit.bwd1,scale="adjr2"))
renderPlot(plot(regbwd.summary1$cp,xlab="Number of Variables",ylab="Cp"))
renderPlot(plot(regbwd.summary1$adjr2,xlab="Number of Variables",ylab="adjr2"))
```

### Random Forest

[Random Forest on yll_abs](https://data.world/tarrantrl/f-17-eda-project-5/insights/e55cacf1-7100-42da-90bf-6bc2df4a3a0a)

The random forest code takes a long time to run, so this is just a sample. See the more accurate results in this insight [here.](https://data.world/tarrantrl/f-17-eda-project-5/insights/e55cacf1-7100-42da-90bf-6bc2df4a3a0a)

```{r}
df_yll_abs_rf=dplyr::select(df, -cause_name, -cause_medium, -cause_short, -region_name, -sex_name, -age_name_unit, -yll_abs_ui_upto, -yll_abs_ui_from)
df_yll_abs_rf=dplyr::sample_n(df_yll_abs_rf, 10000)
df3_nona = na.omit(df_yll_abs_rf)
#attach(df3_nona)
set.seed(101)
dim(df3_nona)
trainrf=sample(1:nrow(df3_nona),1700)
rf.yll_abs=randomForest(yll_abs~.,data=df3_nona,subset=trainrf)
rf.yll_abs
oob.erryll=double(6)
test.erryll=double(6)
for(mtry in 1:6){
  fit=randomForest(yll_abs~.,data=df3_nona,subset=trainrf,mtry=mtry,ntree=50)
  oob.erryll[mtry]=fit$mse[50]
  pred=predict(fit,df3_nona[-trainrf,])
  test.erryll[mtry]=with(df3_nona[-trainrf,],mean((yll_abs-pred)^2))
  cat(mtry," ")
}
```

```{r}
renderPlot({
  matplot(1:mtry,cbind(test.erryll,oob.erryll),pch=19,col=c("red","blue"),type="b",ylab="Mean Squared Error")
  legend("topright",legend=c("OOB","Test"),pch=19,col=c("red","blue"))
})
```

A larger sample and bagging were used in the insight. These results yielded an excellent r-squared value (% variance explained) at 96.05%. 


## Eastern vs Western Europe
From the many regions originally available in the global database, we chose to focus on Eastern and Western Europe. First, we used boosting to find the best predictors for the model. We then looked at Logistic Regression, LDA, QDA, and KNN models to see if the best predictors from boosting would do well in these model types.

### Boosting Model

[Boosting to distinguish eastern and western Europe](https://data.world/tarrantrl/f-17-eda-project-5/insights/d0b1119b-03e3-492b-8389-1ade40af2b55)

[Boosting for region revisited with error](https://data.world/tarrantrl/f-17-eda-project-5/insights/4fa586dd-90ff-4139-bdd5-1833c48e1b00)

```{r}
df_region = df_allyears %>% dplyr::select(.,-cause_name,-year, -sex_name) %>% dplyr::mutate(region_binary = ifelse(region_name == "Eastern Europe", 1, 0)) %>% dplyr::select(.,-region_name)

#%>% dplyr::mutate(region_binary = as.factor(region_binary))
train_region = sample(1:nrow(df_region), 10000)
df_test_region = df_region[-train_region,]
test_region = sample(1:nrow(df_test_region), 10000)

## Boosting 
boost.europe=gbm(region_binary~.,data=df_region[train_region,],distribution="gaussian", n.trees=500,shrinkage=0.01,interaction.depth = 4)
summary(boost.europe, plotit=FALSE)

n.trees=seq(from=100,to=500,by=50)
predmat_region=predict(boost.europe,newdata=df_test_region[test_region,],n.trees=n.trees)
# boosting error
berr_region=with(df_test_region[test_region,],apply( (predmat_region-region_binary)^2,2,mean))
```

```{r}
renderPlot({
  plot(n.trees,berr_region,pch=19,ylab="Mean Squared Error", xlab="# Trees",main="Boosting Test Error")
  abline(h=min(berr_region),col="red")
})
```

We ran 500 trees in this model (for a reasonable loading time), and the prediction error is a lot better than using LR, LDA, or QDA. While those had an accuracy from 51-65%, this model has an error rate that almost gets down to 0.18, corresponding to a prediction accuracy of 82%. The top predictors chosen for this model were yll_rate_ui_upto, daly_rate_ui_upto, daly_abs_ui_from, yld_abs_ui_from, yld_rate_ui_upto.

### Logistic Regression

[Logistic regression for region](https://data.world/tarrantrl/f-17-eda-project-5/insights/8cd11f42-8408-44ba-8599-01f84a6c5627)

Next, we took the top five predictors from boosting and made a logistic regression model.
```{r}
# Logistic Regression
df_region_na = na.omit(df_region)
train_region_na = sample(1:nrow(df_region_na), 10000)
df_test_region_na = df_region_na[-train_region_na,]
test_region_na = sample(1:nrow(df_test_region_na), 10000)
glm.fit.region=glm(region_binary~yll_rate_ui_upto+daly_rate_ui_upto+yld_abs_ui_from+daly_abs_ui_from+yld_rate_ui_upto,data=df_region_na,family=binomial,subset=train_region_na)
summary(glm.fit.region)
glm.probs=predict(glm.fit.region,newdata=df_test_region_na[test_region_na,],type="response")
glm.pred=ifelse(glm.probs>0.5,"1","0")
region.test = df_test_region_na[test_region_na,]$region_binary
table(glm.pred,region.test)
mean(glm.pred==region.test)
```
The prediction accuracy for LR was around 64%, which is significantly worse than the boosting accuracy.

### LDA

[LDA and QDA for region classification](https://data.world/tarrantrl/f-17-eda-project-5/insights/9e6d23b8-58be-4148-a19f-0c5dbacda6c9)

[ROC curve for predicting region](https://data.world/tarrantrl/f-17-eda-project-5/insights/329b7f64-fbfc-47e0-9190-dc770ef387a1)

```{r}
lda.fit.region=lda(region_binary~yll_rate_ui_upto+daly_rate_ui_upto+yld_abs_ui_from+daly_abs_ui_from+yld_rate_ui_upto,data=df_region,subset=train_region)
lda.fit.region
lda.pred=predict(lda.fit.region, df_test_region[test_region,])
lda_df = data.frame(lda.pred)
table(lda.pred$class,df_test_region[test_region,]$region_binary)
mean(lda.pred$class==df_test_region[test_region,]$region_binary)
```
The prediction accuracy for this model was around 54%, which is essentially no better than flipping a coin.

```{r}
predroc2 <- prediction(lda_df$posterior.1,df_test_region[test_region,]$region_binary)
roc.perf = performance(predroc2, measure = "tpr", x.measure = "fpr")

auc1 = performance(predroc2, measure = "auc")
auc1@y.values
```

```{r}
renderPlot({
  plot(roc.perf)
  abline(a=0, b= 1)
})
```


### QDA

```{r}
qda.fit.region=qda(region_binary~yll_rate_ui_upto+daly_rate_ui_upto+yld_abs_ui_from+daly_abs_ui_from+yld_rate_ui_upto,data=df_region,subset=train_region)

qda.fit.region
qda.pred = predict(qda.fit.region, df_test_region[test_region,])
qda_df=data.frame(qda.pred)
table(qda.pred$class,df_test_region[test_region,]$region_binary)
mean(qda.pred$class==df_test_region[test_region,]$region_binary)
```
The prediction accuracy for this was even worse than LDA at around 51%.

```{r}
predroc3 <- prediction(qda_df$posterior.1,df_test_region[test_region,]$region_binary)
roc.perf2 = performance(predroc3, measure = "tpr", x.measure = "fpr")
auc2 = performance(predroc3, measure = "auc")
auc2@y.values
```

```{r}
renderPlot({
  plot(roc.perf2)
  abline(a=0, b= 1)
})
```


### KNN

[KNN for region](https://data.world/tarrantrl/f-17-eda-project-5/insights/8f97ddc5-c6e4-405d-8168-c895a40381dd)

```{r}
# KNN
attach(df_region)

predictorsKNN=cbind(yll_rate_ui_upto,daly_rate_ui_upto,yld_abs_ui_from,daly_abs_ui_from,yld_rate_ui_upto)
knn.pred=class::knn(predictorsKNN[train_region,],predictorsKNN[test_region,],region_binary[train_region],k=1)

table(knn.pred,region_binary[test_region])
mean(knn.pred==region_binary[test_region])
```
KNN did about as well as LR with a prediction accuracy of around 68%.

### K Means Clustering

[K means clustering for region](https://data.world/tarrantrl/f-17-eda-project-5/insights/abcaf28b-e8ca-416f-a41a-6322507d52c8)

In order to gain insight as to why boosting may have done so much better than the other model types, we did K means clustering using two clusters and the top two predictors from boosting.
```{r}
## K means
km_region_x = df_region%>% dplyr::select(yll_rate_ui_upto,daly_rate_ui_upto)
km.out1=kmeans(km_region_x,2)
#km.out1
```

```{r}
renderPlot(plot(km_region_x,col=km.out1$cluster,cex=2,main = "K means clustering", pch=1,lwd=2))
renderPlot(plot(km_region_x,col=as.factor(df_region$region_binary),cex=2,main = "Actual",pch=1,lwd=2))
```
The clustering compared to the real region classification shows that K means is unable to distinguish between the regions in the lower left part of the graph due to extreme overlap. However, the upper right is dominated by one class. Perhaps the simpler model types are unable to distinguish between the classes due to overlap. However, the slow learning quality of boosting may allow it to find the nuanced differences between the classes. 

## Support Vector Machine: Multiple Sclerosis for Male vs Females

[Linear SVM on Yld Rate ~ Death Rate for Multiple Sclerosis](https://data.world/tarrantrl/f-17-eda-project-5/insights/b04d895b-d6a9-494d-80cd-ed9728a1f634)

We used support vector machines to classify the Yld Rate vs Death Rate plot for Multiple Sclerosis in Europe by male and female points.
First we used a linear SVM:

```{r}
dfe_ms = df %>% dplyr::filter(region_name %in% c("Eastern Europe", "Western Europe") & sex_name %in% c("Male", "Female") & cause_name %in% c("Multiple sclerosis") & age_name_unit == "years")

x_try=subset(dfe_ms, select = c(death_rate, yld_rate))
x_svm=matrix(unlist(x_try), ncol = 2)
y_svm=dfe_ms$sex_name
dat=data.frame(x_svm,y_svm)
svmfit=svm(y_svm~.,data=dat,type="C-classification",kernel="linear",cost=10,scale=FALSE)
```

```{r}
make.grid=function(x,n=100){
  grange=apply(x,2,range)
  x1=seq(from=grange[1,1],to=grange[2,1],length=n)
  x2=seq(from=grange[1,2],to=grange[2,2],length=n)
  expand.grid(X1=x1,X2=x2)
}
xgrid=make.grid(x_svm)
ygrid=predict(svmfit,xgrid)

beta=drop(t(svmfit$coefs)%*%x_svm[svmfit$index,])
beta0=svmfit$rho
tonum=function(ysvm){
  tonumberdf = dfe_ms %>% dplyr::mutate(sex_name2 = ifelse(sex_name == "Male", 1, 0))
  tonumberdf$sex_name2
}
renderPlot({
  plot(xgrid,col=c("yellow","blue")[as.numeric(ygrid)],pch=20,cex=.2)
  points(x_svm,col=tonum(df)+2,pch=19)
  points(x_svm[svmfit$index,],pch=5,cex=2)
  abline(beta0/beta[2],-beta[1]/beta[2])
  abline((beta0-1)/beta[2],-beta[1]/beta[2],lty=2)
  abline((beta0+1)/beta[2],-beta[1]/beta[2],lty=2)
})
```

As you can see, the linear decision boundary puts most of the female points (red) on the top and most of the male points on the bottom of the boundary. A large amount of the points are support vector points. Unfortunately, it has very large margins probably because the separation between the classes is not linear. Thus we used a radial kernel next:

[Radial SVM on Yld Rate ~ Death Rate for Multiple Sclerosis](https://data.world/tarrantrl/f-17-eda-project-5/insights/79072de3-484f-45cc-aa74-82f8cfda6589)

```{r}
x_try2=subset(dfe_ms, select = c(yld_rate, death_rate))
x_svm2=matrix(unlist(x_try2), ncol = 2)
dat2=data.frame(x_svm2,y_svm)
nlsvmfit=svm(y_svm~.,data=dat2,type="nu-classification",scale=TRUE,kernel="radial",cost=10)
```
```{r}
renderPlot(plot(nlsvmfit, dat2))
```

The radial kernel did a much better job. It makes it clear that the female points are shifted to the upper right of the male points. This lead us to an interesting finding:
Women with multiple sclerosis tend to have a higher death rate and higher rate of years lived with disability than men.  

## Unsupervised Learning

### K-means Clustering

[K means clustering on Ischemic Heart Disease and Stroke](https://data.world/tarrantrl/f-17-eda-project-5/insights/c055cd89-0846-444a-a63c-bcf5c80f7746)

```{r}
dfe_heart = df %>% dplyr::filter(region_name %in% c("Eastern Europe", "Western Europe") & cause_name %in% c("Ischemic heart disease", "Ischemic stroke") & age_name_unit == "years")
x_km = dfe_heart%>%dplyr::select(yld_rate, yll_rate)
km.out=kmeans(x_km,2)
```

```{r}
renderPlot(plot(x_km,col=as.factor(dfe_heart$region_name),cex=2,main = "Actual",pch=1,lwd=2))
renderPlot(plot(x_km,col=km.out$cluster,cex=2,main = "K means clustering", pch=1,lwd=2))
```

Interesting finding: After looking at a scatterplot of yld_rate vs yll_rate for only data regarding Ischemic heart disease and stroke in Europe, we noticed a natural separation between Western and Eastern Europe (on top). Interestingly, K-means clustering didn't separate the data as we would have expected it to, which was possibly due to one of the centroids used by the analysis being focused in a highly clustered area (data points from both regions were very close together). Data around the other centroid had points that were mostly belonging to Eastern Europe, which was mostly correct. Had our data been a bit more spread out, K-means clustering may have done a better job. 


### Hierarchical Clustering 

[Hierarchical Clustering on Ischemic Heart Disease and Stroke](https://data.world/tarrantrl/f-17-eda-project-5/insights/d8c6a10b-e3f5-4e5d-ba96-07aa2dc164f8)

```{r}
hc.complete=hclust(dist(x_km),method="complete")
hc.single=hclust(dist(x_km),method="single")
hc.average=hclust(dist(x_km),method="average")
hc.cut1=cutree(hc.complete,2)
hc.cut2=cutree(hc.single,2)
hc.cut3=cutree(hc.average,2)
```

```{r}
renderPlot(plot(x_km,col=hc.cut1,cex=2,main = "Hierarchical: Complete", pch=1,lwd=2))
renderPlot(plot(x_km,col=hc.cut2,cex=2,main = "Hierarchical: Single", pch=1,lwd=2))
renderPlot(plot(x_km,col=hc.cut3,cex=2,main = "Hierarchical: Average", pch=1,lwd=2))
```

Compared to K-means clustering, hierarchical clustering (complete, single, and average) did a much worse job. Overall, the closest Hierarchical came to K-means results (which were already not perfect), was using the complete method. 

### PCA on subset of data

[PCA on Subset of the Data](https://data.world/tarrantrl/f-17-eda-project-5/insights/03e1d5df-1b45-4ba9-a218-ceef43276330)

```{r}
df_subset2 <- df %>% dplyr::select(., -cause_name, -cause_medium, -cause_short, -region_name, -year, -age_name_unit, -sex_name)
df_nona_pca <- na.omit(df_subset2)
#attach(df_nona_pca)
#dimnames(df_nona_pca)
apply(df_nona_pca,2,mean)
apply(df_nona_pca,2, var)
pca.out=prcomp(df_nona_pca, scale=TRUE)
pca.out
names(pca.out)
```

To see the graph:
[PCA on Subset of the Data](https://data.world/tarrantrl/f-17-eda-project-5/insights/03e1d5df-1b45-4ba9-a218-ceef43276330)

Interesting finding: The predictors displayed in the biplot of this analysis were clustered by type (death rate predictors grouped together, years of life lost predictors grouped together, etc.). This makes sense, considering they are usually pretty standard variations of each other. Most of the datapoints are clustered around the center here, with very few of them straying to the bottom right. This may be taken to mean that there isn't much variance in our data.


## Insights

[First Attempt at Best Subset Selection Predicting Cause](https://data.world/tarrantrl/f-17-eda-project-5/insights/01a30c5e-ac21-4b5e-867c-5ddc2f7e5e21)

[KNN on Cause](https://data.world/tarrantrl/f-17-eda-project-5/insights/473800c5-aa3e-4d22-9110-231e17944d4d)

[Pairs charts between subsets of predictors](https://data.world/tarrantrl/f-17-eda-project-5/insights/a1cd6a73-b94d-4c0e-af4b-3fa5beb40834)

[Boosting to find important predictors for death_abs](https://data.world/tarrantrl/f-17-eda-project-5/insights/26c94e87-2611-4bcc-b851-6d938ff1e45d)

[Multi-predictor Linear Regression Model for death_abs](https://data.world/tarrantrl/f-17-eda-project-5/insights/2c1db0df-9dae-4b4c-a816-d862f903a179)

[Boosting to Find Best Predictors of yll_abs](https://data.world/tarrantrl/f-17-eda-project-5/insights/743d8695-b85b-49ac-b537-05f0b554b809)

[Backwards, Forwards, and Best Subset Selection for death_abs](https://data.world/tarrantrl/f-17-eda-project-5/insights/3350db18-efb4-4359-92bd-c64b0f3274f5)

[Lasso on death_abs](https://data.world/tarrantrl/f-17-eda-project-5/insights/2d587ac9-73ff-49ec-9b48-1094cca839b1)

[Linear Regression on death_abs with Updated Predictors](https://data.world/tarrantrl/f-17-eda-project-5/insights/b4a21227-5c31-4120-9b0e-0c2e7207c9fc)

[Lasso Analysis on yll_abs](https://data.world/tarrantrl/f-17-eda-project-5/insights/5ff96be6-c362-4ae9-bd61-6e5c9409b0da)

[K means clustering on Ischemic Heart Disease and Stroke](https://data.world/tarrantrl/f-17-eda-project-5/insights/c055cd89-0846-444a-a63c-bcf5c80f7746)

[Linear Regression on yll_abs](https://data.world/tarrantrl/f-17-eda-project-5/insights/8593766c-f3de-4a3d-a054-a91dc9130785)

[Hierarchical Clustering on Ischemic Heart Disease and Stroke](https://data.world/tarrantrl/f-17-eda-project-5/insights/d8c6a10b-e3f5-4e5d-ba96-07aa2dc164f8)

[Cause of death](https://data.world/tarrantrl/f-17-eda-project-5/insights/1c0d5968-d862-429d-bc27-77f72e3a9f73)

[Lasso on region_name](https://data.world/tarrantrl/f-17-eda-project-5/insights/fffa3067-a1e1-451a-8159-e1aeb1a0bb79)

[PCA on Subset of the Data](https://data.world/tarrantrl/f-17-eda-project-5/insights/03e1d5df-1b45-4ba9-a218-ceef43276330)

[Boosting to predict cancer class](https://data.world/tarrantrl/f-17-eda-project-5/insights/4f220f02-ae27-4095-9491-19724fb702fc)

[Linear SVM on Yld Rate ~ Death Rate for Multiple Sclerosis](https://data.world/tarrantrl/f-17-eda-project-5/insights/b04d895b-d6a9-494d-80cd-ed9728a1f634)

[Radial SVM on Yld Rate ~ Death Rate for Multiple Sclerosis](https://data.world/tarrantrl/f-17-eda-project-5/insights/79072de3-484f-45cc-aa74-82f8cfda6589)

[Random Forest on death_abs](https://data.world/tarrantrl/f-17-eda-project-5/insights/230157c7-8aed-4067-b57f-6b8bf34ab6f6)

[Boosting to distinguish eastern and western Europe](https://data.world/tarrantrl/f-17-eda-project-5/insights/d0b1119b-03e3-492b-8389-1ade40af2b55)

[Best Subset Selection for yll_abs](https://data.world/tarrantrl/f-17-eda-project-5/insights/e85e9b69-9203-4244-ad1d-a543c6c76036)

[Logistic regression for region](https://data.world/tarrantrl/f-17-eda-project-5/insights/8cd11f42-8408-44ba-8599-01f84a6c5627)

[Forward & Backwards Selection of yll_abs](https://data.world/tarrantrl/f-17-eda-project-5/insights/32178177-a72b-4064-a6e2-07a6422034e9)

[LDA and QDA for region classification](https://data.world/tarrantrl/f-17-eda-project-5/insights/9e6d23b8-58be-4148-a19f-0c5dbacda6c9)

[Boosting to distinguish Male and Female](https://data.world/tarrantrl/f-17-eda-project-5/insights/45e1626b-fdfc-4543-90f1-61b2dae599af)

[Random Forest on yll_abs](https://data.world/tarrantrl/f-17-eda-project-5/insights/e55cacf1-7100-42da-90bf-6bc2df4a3a0a)

[LDA to predict sex](https://data.world/tarrantrl/f-17-eda-project-5/insights/546d9d99-645b-4454-b330-a1064e03b02f)

[ROC curve for prediction of sex](https://data.world/tarrantrl/f-17-eda-project-5/insights/179ec2db-7e86-4e53-b915-27a6df1c4eea)

[ROC curve for predicting region](https://data.world/tarrantrl/f-17-eda-project-5/insights/329b7f64-fbfc-47e0-9190-dc770ef387a1)

[Boosting for region revisited with error](https://data.world/tarrantrl/f-17-eda-project-5/insights/4fa586dd-90ff-4139-bdd5-1833c48e1b00)

[KNN for region](https://data.world/tarrantrl/f-17-eda-project-5/insights/8f97ddc5-c6e4-405d-8168-c895a40381dd)

[K means clustering for region](https://data.world/tarrantrl/f-17-eda-project-5/insights/abcaf28b-e8ca-416f-a41a-6322507d52c8)

[Boosting to Find Best Predictors of yld_abs](https://data.world/tarrantrl/f-17-eda-project-5/insights/9fa7fa8b-13b6-4e72-ae9c-03b558fee303)

[Lasso on yld_abs](https://data.world/tarrantrl/f-17-eda-project-5/insights/0f970af9-b27c-4049-aef1-1e79ee846b33)

[Linear Regression on yld_abs](https://data.world/tarrantrl/f-17-eda-project-5/insights/07a06299-cdac-4027-89fc-affed3ef0ec0)

[Linear Regression on yld_abs with Lasso Predictors](https://data.world/tarrantrl/f-17-eda-project-5/insights/89615283-c198-4282-a4de-3b2308414449)

[Residual Analysis with Death_abs](https://data.world/tarrantrl/f-17-eda-project-5/insights/4e1e3b1b-cd4a-4a3c-b462-610ace7657fe)


